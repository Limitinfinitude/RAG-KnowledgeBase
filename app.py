# app.py
import streamlit as st
import time

from langchain_core.messages import HumanMessage, AIMessage

from config import *
from utils.embedding import get_embeddings, get_reranker
from utils.db import get_vector_db
from chains.intent_rephrase import rephrase_chain
from chains.qa_chain import qa_chain, llm
from components.sidebar import render_sidebar

# ------------------- Streamlit é¡µé¢é…ç½® -------------------
st.set_page_config(page_title="ä¼ä¸šçº§ RAG æ’æŸ¥åŠ©æ‰‹", layout="wide")
st.title("ğŸ›¡ï¸ ä¸¥æ ¼çº¦æŸå‹ RAG åŠ©æ‰‹")

# ------------------- ç¼“å­˜åŠ è½½æ ¸å¿ƒå¼•æ“ -------------------
@st.cache_resource
def load_engines():
    embeddings = get_embeddings()
    reranker = get_reranker()
    vector_db = get_vector_db(embeddings)
    return vector_db, reranker

vector_db, reranker = load_engines()

# ------------------- ä¾§è¾¹æ  -------------------
selected_doc = render_sidebar(vector_db)

# ------------------- ä¼šè¯çŠ¶æ€åˆå§‹åŒ– -------------------
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ------------------- æ˜¾ç¤ºå†å²æ¶ˆæ¯ -------------------
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ------------------- æ£€ç´¢å‡½æ•°ï¼ˆå¸¦è®¡æ—¶ï¼‰ -------------------
def manual_retrieve(query: str, selected_doc: str, k: int = 15):
    start_time = time.perf_counter()

    search_kwargs = {"k": k}
    if selected_doc != "å…¨éƒ¨æ–‡æ¡£":
        search_kwargs["filter"] = {"source_file": selected_doc}

    initial_docs = vector_db.similarity_search(query, **search_kwargs)
    if not initial_docs:
        retrieve_time = time.perf_counter() - start_time
        st.caption(f"æ£€ç´¢è€—æ—¶: {retrieve_time:.2f} ç§’ï¼ˆæœªå‘½ä¸­ï¼‰")
        return [], ""

    pairs = [[query, doc.page_content] for doc in initial_docs]
    scores = reranker.predict(pairs)
    scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)

    # ä¿å­˜æœ¬æ¬¡æ£€ç´¢ç»“æœï¼Œç”¨äºæº¯æºå±•ç¤º
    st.session_state.last_search_results = scored_docs[:5]
    context = "\n\n".join([d[0].page_content for d in scored_docs[:3]])

    retrieve_time = time.perf_counter() - start_time
    st.caption(f"æ£€ç´¢è€—æ—¶: {retrieve_time:.2f} ç§’")
    return scored_docs, context

# ------------------- ç”¨æˆ·è¾“å…¥å¤„ç† -------------------
if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æœ¬æ¬¡å¯¹è¯ LLM è°ƒç”¨è®¡æ•°ä¸æ€»è®¡æ—¶
    llm_call_count = 0
    total_start_time = time.perf_counter()

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        # 1. æ„å›¾è¯†åˆ« + æŸ¥è¯¢æ”¹å†™ï¼ˆç¬¬1æ¬¡ LLM è°ƒç”¨ï¼‰
        llm_call_count += 1
        response = rephrase_chain.invoke({
            "input": user_input,
            "chat_history": st.session_state.chat_history
        })
        lines = response.strip().split("\n")
        intent = lines[0].strip().upper() if len(lines) >= 1 else "CHAT"
        standalone_q = lines[1].strip() if len(lines) >= 2 else user_input

        if intent == "CHAT":
            # çº¯é—²èŠï¼Œç›´æ¥è°ƒç”¨ LLM
            llm_call_count += 1
            answer = st.write_stream(llm.stream(user_input))
        else:
            # RAG æµç¨‹
            st.info(f"ğŸ” æ£€ç´¢å…³é”®è¯ï¼š{standalone_q}")

            with st.spinner("æ·±åº¦æ£€ç´¢ä¸åˆ†æèµ„æ–™ä¸­..."):
                top_docs, context_text = manual_retrieve(standalone_q, selected_doc)

                if not context_text:
                    answer = "æŠ±æ­‰ï¼Œæœªåœ¨æ–‡æ¡£åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¾æ®ã€‚"
                    st.markdown(answer)
                else:
                    llm_call_count += 1
                    answer = st.write_stream(qa_chain.stream({
                        "context": context_text,
                        "chat_history": st.session_state.chat_history,
                        "input": standalone_q
                    }))

            # æ˜¾ç¤ºæº¯æºä¿¡æ¯
            if st.session_state.get("last_search_results"):
                with st.expander("ğŸ” åŒ¹é…è¯¦æƒ…ä¸æº¯æºå¾—åˆ† (Top 5)"):
                    for doc, score in st.session_state.last_search_results:
                        color = "green" if score > 0 else "gray"
                        st.write(
                            f"æ–‡ä»¶: **{doc.metadata.get('source_file', 'æœªçŸ¥')}** | "
                            f"è¯­ä¹‰å…³è”åº¦: :{color}[{round(float(score), 3)}]"
                        )
                        st.caption(doc.page_content)
                        st.divider()

        # æ›´æ–°ä¼šè¯å†å²
        st.session_state.chat_history.extend([
            HumanMessage(content=user_input),
            AIMessage(content=answer)
        ])
        st.session_state.messages.append({"role": "assistant", "content": answer})

    # ------------------- è°ƒè¯•ä¿¡æ¯ -------------------
    total_time = time.perf_counter() - total_start_time
    with st.chat_message("assistant"):
        st.caption("è°ƒè¯•ä¿¡æ¯ï¼š")
        st.caption(f"- LLM è°ƒç”¨æ¬¡æ•°: {llm_call_count} æ¬¡")
        st.caption(f"- æ€»å“åº”æ—¶é—´: {total_time:.2f} ç§’")