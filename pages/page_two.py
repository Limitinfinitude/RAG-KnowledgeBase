# pages/page_two.py
import streamlit as st
import os
import shutil
from datetime import datetime
from config import DB_DIR
from utils.file_loader import ingest_file
from utils.embedding import get_embeddings
from utils.db import get_vector_db
import utils.ui_utils
utils.ui_utils.load_custom_css()
st.title("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
# pages/page_two.py é¡¶éƒ¨ä¹ŸåŠ ä¸€éï¼ˆä¿é™©ï¼‰
if "model_mode" not in st.session_state:
    st.session_state.model_mode = "API è°ƒç”¨ (OpenAI)"
    st.session_state.ollama_base_url = "http://localhost:11434"
    st.session_state.ollama_model = "qwen2.5:7b"
# é‡æ–°åŠ è½½å‘é‡åº“ï¼ˆç®¡ç†é¡µé¢ç‹¬ç«‹ï¼‰
embeddings = get_embeddings()
vector_db = get_vector_db(embeddings)

index_dir = os.path.join(DB_DIR, "faiss_index")

# ------------------- ä¸Šä¼ æ–‡æ¡£ -------------------
st.subheader("ğŸ“¤ ä¸Šä¼ æ–°æ–‡æ¡£")
uploaded_files = st.file_uploader(
    "é€‰æ‹© PDF æˆ– TXT æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
    accept_multiple_files=True,
    type=["pdf", "txt"],
    key="kb_upload_page_two"
)

if st.button("ğŸ”„ å¼€å§‹å…¥åº“", type="primary"):
    if uploaded_files:
        with st.spinner("æ­£åœ¨å¤„ç†å¹¶å…¥åº“..."):
            total_chunks = 0
            for file in uploaded_files:
                total_chunks += ingest_file(file, vector_db)
            # å…¥åº“åç«‹å³ä¿å­˜
            os.makedirs(index_dir, exist_ok=True)
            vector_db.save_local(index_dir)
            st.success(f"æˆåŠŸå…¥åº“ {total_chunks} ä¸ªæ–‡æœ¬å—")
            st.rerun()
    else:
        st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶")

# ------------------- å·²ä¸Šä¼ æ–‡æ¡£åˆ—è¡¨ -------------------
st.subheader("ğŸ“‹ å·²ä¸Šä¼ æ–‡æ¡£åˆ—è¡¨")
try:
    docs = vector_db.similarity_search("", k=30000)
    real_docs = [d for d in docs if d.metadata.get("source_file") not in ["system", None]]

    if real_docs:
        from collections import defaultdict
        stats = defaultdict(lambda: {"chunks": 0, "type": ""})
        for d in real_docs:
            name = d.metadata["source_file"]
            stats[name]["chunks"] += 1
            stats[name]["type"] = "PDF" if name.lower().endswith(".pdf") else "TXT"

        data = [
            {
                "æ–‡æ¡£åç§°": name,
                "åˆ†å—æ•°é‡": info["chunks"],
                "æ–‡ä»¶ç±»å‹": info["type"],
                "ä¸Šä¼ æ—¶é—´": "æœªçŸ¥"  # å¯åç»­åŠ æ—¶é—´å…ƒæ•°æ®
            }
            for name, info in stats.items()
        ]
        st.dataframe(data, use_container_width=True)
    else:
        st.info("çŸ¥è¯†åº“ä¸­æš‚æ— æ–‡æ¡£")
except Exception as e:
    st.error(f"è¯»å–å¤±è´¥: {e}")

# ------------------- ç´¢å¼•ç®¡ç† -------------------
st.subheader("ğŸ—„ï¸ ç´¢å¼•æ“ä½œ")
c1, c2, c3 = st.columns(3)

with c1:
    if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜ç´¢å¼•"):
        os.makedirs(index_dir, exist_ok=True)
        vector_db.save_local(index_dir)
        st.success("ç´¢å¼•å·²ä¿å­˜")

with c2:
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“"):
        if st.checkbox("âš ï¸ ç¡®è®¤æ¸…ç©ºï¼ˆä¸å¯æ¢å¤ï¼‰"):
            if os.path.exists(index_dir):
                shutil.rmtree(index_dir)
                st.success("çŸ¥è¯†åº“å·²æ¸…ç©º")
                st.rerun()

with c3:
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç´¢å¼•å¤‡ä»½",
        data="æ‰‹åŠ¨å¤‡ä»½è¯·å¤åˆ¶ faiss_index æ–‡ä»¶å¤¹",
        file_name="backup_instruction.txt",
        help="FAISS ç´¢å¼•ä¸ºæ–‡ä»¶å¤¹å½¢å¼ï¼Œè¯·ç›´æ¥å¤åˆ¶ knowledge_db/faiss_index"
    )

st.caption(f"ç´¢å¼•å­˜å‚¨è·¯å¾„ï¼š`{index_dir}`")