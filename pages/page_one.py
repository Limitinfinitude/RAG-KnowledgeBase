# pages/page_one.py
import streamlit as st
import time
import requests
from datetime import datetime
from typing import Optional

# å¯¼å…¥æ¨¡å—åŒ–UI
import utils.ui_utils

# ------------------- å­é¡µé¢åŠ è½½è‡ªå®šä¹‰CSSï¼ˆå…³é”®ï¼ï¼‰ -------------------
utils.ui_utils.load_custom_css()  # â† å¿…é¡»åŠ è¿™ä¸€è¡Œï¼Œè®©å­é¡µé¢ä¹Ÿæœ‰æ ·å¼

# ------------------- å¯¼å…¥æ ¸å¿ƒæ¨¡å— -------------------
from config import *
from utils.embedding import get_embeddings, get_reranker
from utils.db import get_vector_db
from langchain_openai import ChatOpenAI
from langchain_community.llms import Ollama
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# ------------------- ä¼šè¯çŠ¶æ€åˆå§‹åŒ– -------------------
if "model_mode" not in st.session_state:
    st.session_state.model_mode = "API è°ƒç”¨ (OpenAI)"
    st.session_state.ollama_base_url = "http://localhost:11434"
    st.session_state.ollama_model = "qwen2.5:7b"

if "conversations" not in st.session_state:
    st.session_state.conversations = {
        "é»˜è®¤å¯¹è¯": {"messages": [], "chat_history": []}
    }
if "current_conversation" not in st.session_state:
    st.session_state.current_conversation = "é»˜è®¤å¯¹è¯"

# å½“å‰å¯¹è¯å¿«æ·å¼•ç”¨
current_conv = st.session_state.conversations[st.session_state.current_conversation]
st.session_state.messages = current_conv["messages"]
st.session_state.chat_history = current_conv["chat_history"]

# ------------------- åŠ è½½æ ¸å¿ƒå¼•æ“ -------------------
@st.cache_resource
def load_engines():
    embeddings = get_embeddings()
    reranker = get_reranker()
    vector_db = get_vector_db(embeddings)
    return vector_db, reranker

vector_db, reranker = load_engines()

# ------------------- ä¾§è¾¹æ ï¼šå¯¹è¯ç®¡ç†ï¼ˆç±» Grok ä¸“ä¸šç‰ˆï¼‰ -------------------
with st.sidebar:
    st.markdown("### å¯¹è¯ç®¡ç†")

    # æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("â• æ–°å»ºå¯¹è¯", use_container_width=True, key="new_conversation_btn", type="secondary"):
        new_name = f"æ–°å¯¹è¯ {len(st.session_state.conversations) + 1}"
        st.session_state.conversations[new_name] = {"messages": [], "chat_history": []}
        st.session_state.current_conversation = new_name
        st.rerun()

    st.markdown("---")

    # ä½ çš„å¯¹è¯ï¼ˆå¯æŠ˜å ï¼‰
    with st.expander("ä½ çš„å¯¹è¯", expanded=True):
        if st.session_state.conversations:
            conv_names = list(st.session_state.conversations.keys())

            for conv_name in conv_names:
                col_left, col_right = st.columns([6, 1])

                with col_left:
                    is_active = st.session_state.current_conversation == conv_name
                    if st.button(
                        conv_name,
                        key=f"switch_{conv_name}",
                        use_container_width=True,
                        type="primary" if is_active else "secondary"
                    ):
                        if not is_active:
                            st.session_state.current_conversation = conv_name
                            current_conv = st.session_state.conversations[conv_name]
                            st.session_state.messages = current_conv["messages"]
                            st.session_state.chat_history = current_conv["chat_history"]
                            st.rerun()

                with col_right:
                    with st.popover("â‹®", use_container_width=True):
                        st.markdown(f"**{conv_name}**")

                        new_name = st.text_input("é‡å‘½å", value=conv_name, key=f"rename_{conv_name}")
                        if st.button("ğŸ’¾ ä¿å­˜", key=f"save_rename_{conv_name}"):
                            if new_name.strip() and new_name != conv_name:
                                if new_name not in st.session_state.conversations:
                                    st.session_state.conversations[new_name] = st.session_state.conversations.pop(conv_name)
                                    if st.session_state.current_conversation == conv_name:
                                        st.session_state.current_conversation = new_name
                                    st.success("é‡å‘½åæˆåŠŸ")
                                    st.rerun()
                                else:
                                    st.error("åç§°å·²å­˜åœ¨")
                            else:
                                st.warning("åç§°æœªæ”¹å˜æˆ–ä¸ºç©º")

                        if st.button("ğŸ—‘ï¸ åˆ é™¤", type="secondary", key=f"delete_{conv_name}"):
                            if len(st.session_state.conversations) > 1:
                                del st.session_state.conversations[conv_name]
                                if st.session_state.current_conversation == conv_name:
                                    new_current = next(iter(st.session_state.conversations))
                                    st.session_state.current_conversation = new_current
                                    current_conv = st.session_state.conversations[new_current]
                                    st.session_state.messages = current_conv["messages"]
                                    st.session_state.chat_history = current_conv["chat_history"]
                                st.success("å·²åˆ é™¤")
                                st.rerun()
                            else:
                                st.error("ä¸èƒ½åˆ é™¤æœ€åä¸€ä¸ªå¯¹è¯")

                        if st.button("ğŸ“Œ ç½®é¡¶", key=f"pin_{conv_name}"):
                            if conv_name != conv_names[0]:
                                items = list(st.session_state.conversations.items())
                                pinned = [(conv_name, st.session_state.conversations[conv_name])]
                                others = [i for i in items if i[0] != conv_name]
                                st.session_state.conversations = dict(pinned + others)
                                st.success("å·²ç½®é¡¶")
                                st.rerun()

                st.markdown("<hr style='margin: 10px 0; border: none; border-top: 1px solid #e2e8f0;'>", unsafe_allow_html=True)
        else:
            st.info("æš‚æ— å¯¹è¯ï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®åˆ›å»º")

# ------------------- ä¸»é¡µé¢å†…å®¹ -------------------
utils.ui_utils.render_header()
chat_container = utils.ui_utils.render_chat_history()
user_input = utils.ui_utils.render_chat_input()

# ------------------- åˆå§‹åŒ–LLM -------------------
if st.session_state.model_mode == "æœ¬åœ°è°ƒç”¨ (Ollama)":
    llm = Ollama(
        model=st.session_state.ollama_model,
        base_url=st.session_state.ollama_base_url,
        temperature=0
    )
else:
    llm = ChatOpenAI(
        model=LLM_MODEL,
        api_key=API_KEY,
        base_url=BASE_URL,
        temperature=0
    )

# ------------------- Chain å®šä¹‰ -------------------
rephrase_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š
1. å¦‚æœæ˜¯é—²èŠ/æ— å…³é—®é¢˜ï¼Œç›´æ¥å›å¤'CHAT'å¹¶åœ¨ä¸‹ä¸€è¡Œè¾“å‡ºåŸé—®é¢˜ã€‚
2. å¦‚æœæ˜¯çŸ¥è¯†æŸ¥è¯¢/éœ€è¦æ£€ç´¢çš„é—®é¢˜ï¼Œå›å¤'RAG'å¹¶åœ¨ä¸‹ä¸€è¡Œè¾“å‡ºä¼˜åŒ–åçš„æ£€ç´¢è¯­å¥ã€‚
åªè¾“å‡ºä¸¤è¡Œï¼š
ç¬¬ä¸€è¡Œï¼šæ„å›¾ï¼ˆCHAT æˆ– RAGï¼‰
ç¬¬äºŒè¡Œï¼šæœ€ç»ˆè¯­å¥"""),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

qa_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªåŸºäºæ–‡æ¡£çš„ã€æ€»ç»“ä¸äº‹å®é™ˆè¿°ã€‘åŠ©æ‰‹ã€‚
ã€æ ¸å¿ƒä»»åŠ¡ã€‘ï¼š
1. æ ¹æ®ã€æ–‡æ¡£èµ„æ–™ã€‘å†…å®¹ï¼Œæ€»ç»“å¹¶å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
2. å¦‚æœèµ„æ–™ä¸­çš„æè¿°ä¸ç”¨æˆ·æé—®æ„æ€ä¸€è‡´ï¼Œè¯·è¿›è¡Œå…³è”å¹¶ç»™å‡ºäº‹å®æ€»ç»“ã€‚
3. ä¸¥ç¦æåŠèµ„æ–™ä¸­å®Œå…¨ä¸å­˜åœ¨çš„è™šå‡äº‹å®ã€‚
4. å›ç­”å¿…é¡»ä½“ç°å‡ºæ˜¯ä»èµ„æ–™ä¸­æ€»ç»“å‡ºæ¥çš„ã€‚
ã€çº¦æŸã€‘ï¼š
- å¦‚æœèµ„æ–™é‡Œæ²¡æœ‰ç›¸å…³åŠ¨ä½œçš„æè¿°ï¼Œæ‰å›ç­”"æ ¹æ®ç°æœ‰èµ„æ–™æ— æ³•å›ç­”"ã€‚
- ä¸è¦ä½¿ç”¨ä»»ä½•å¤–éƒ¨å¸¸è¯†ã€‚
ã€æ–‡æ¡£èµ„æ–™ã€‘ï¼š
{context}"""),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

rephrase_chain = rephrase_prompt | llm | StrOutputParser()
qa_chain = qa_prompt | llm | StrOutputParser()

# ------------------- æ£€ç´¢å‡½æ•° -------------------
def manual_retrieve(query: str, selected_doc: str, k: int = 15):
    start_time = time.perf_counter()
    search_kwargs = {"k": k}
    if selected_doc != "å…¨éƒ¨æ–‡æ¡£":
        search_kwargs["filter"] = {"source_file": selected_doc}

    initial_docs = vector_db.similarity_search(query, **search_kwargs)
    if not initial_docs:
        st.caption(f"â±ï¸ æ£€ç´¢è€—æ—¶: {time.perf_counter() - start_time:.2f} ç§’ï¼ˆæœªå‘½ä¸­ï¼‰")
        return [], ""

    pairs = [[query, doc.page_content] for doc in initial_docs]
    scores = reranker.predict(pairs)
    scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)

    st.session_state.last_search_results = scored_docs[:5]
    context = "\n\n".join([d[0].page_content for d in scored_docs[:3]])
    st.caption(f"â±ï¸ æ£€ç´¢è€—æ—¶: {time.perf_counter() - start_time:.2f} ç§’")
    return scored_docs, context

# ------------------- å›ºå®šå·¦ä¸‹è§’æ£€ç´¢èŒƒå›´ï¼ˆå®šä¹‰ selected_doc åœ¨å…¨å±€ï¼‰ -------------------
st.markdown("""
    <style>
    .fixed-filter {
        position: fixed;
        bottom: 80px;
        left: 20px;
        background: white;
        padding: 12px 16px;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.15);
        border: 1px solid #e2e8f0;
        z-index: 1000;
        max-width: 280px;
        font-size: 0.9rem;
    }
    </style>
""", unsafe_allow_html=True)

try:
    docs = vector_db.similarity_search("", k=10000)
    all_sources = list(set(
        d.metadata.get("source_file", "æœªçŸ¥")
        for d in docs
        if d.metadata.get("source_file") not in ["system"]
    ))
except Exception:
    all_sources = []

with st.container():
    st.markdown('<div class="fixed-filter">', unsafe_allow_html=True)
    st.markdown("**ğŸ¯ æ£€ç´¢èŒƒå›´**")
    selected_doc = st.selectbox(
        "é€‰æ‹©çŸ¥è¯†åº“",
        ["å…¨éƒ¨æ–‡æ¡£"] + sorted(all_sources),
        index=0,
        key="global_doc_filter",
        label_visibility="collapsed"
    )
    st.markdown(f"<small>å½“å‰ï¼š<strong>{selected_doc}</strong></small>", unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

# ------------------- ç”¨æˆ·è¾“å…¥å¤„ç† -------------------
if user_input:
    llm_call_count = 0
    total_start_time = time.perf_counter()

    st.session_state.messages.append({"role": "user", "content": user_input})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            llm_call_count += 1
            with st.spinner("ğŸ¤– åˆ†æé—®é¢˜æ„å›¾..."):
                response = rephrase_chain.invoke({
                    "input": user_input,
                    "chat_history": st.session_state.chat_history
                })
            lines = response.strip().split("\n", 1)
            intent = lines[0].strip().upper() if lines else "CHAT"
            standalone_q = lines[1].strip() if len(lines) > 1 else user_input

            if intent == "CHAT":
                st.markdown("""<div class="info-box"><strong>ğŸ’¬ å¯¹è¯æ¨¡å¼ï¼š</strong>ç›´æ¥å›ç­”ï¼ˆæ— éœ€æ£€ç´¢ï¼‰</div>""", unsafe_allow_html=True)
                llm_call_count += 1
                answer = st.write_stream(llm.stream(user_input))
            else:
                st.markdown(f"""
                    <div class="info-box">
                        <strong>ğŸ” æ£€ç´¢æ¨¡å¼ï¼š</strong>åŸºäºçŸ¥è¯†åº“å›ç­”<br>
                        <strong>æ£€ç´¢å…³é”®è¯ï¼š</strong>{standalone_q}
                    </div>
                """, unsafe_allow_html=True)

                with st.spinner("ğŸ“š æ·±åº¦æ£€ç´¢ä¸åˆ†ææ–‡æ¡£..."):
                    top_docs, context_text = manual_retrieve(standalone_q, selected_doc)  # ä½¿ç”¨å·¦ä¸‹è§’çš„ selected_doc

                    if not context_text:
                        answer = "ğŸ¤· æŠ±æ­‰ï¼Œæœªåœ¨æ–‡æ¡£åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¾æ®ã€‚"
                        st.markdown(f"<div class='warning-box'><strong>æç¤ºï¼š</strong>{answer}</div>", unsafe_allow_html=True)
                    else:
                        llm_call_count += 1
                        st.markdown("ğŸ¯ æ­£åœ¨ç”ŸæˆåŸºäºæ–‡æ¡£çš„å›ç­”...")
                        answer = st.write_stream(qa_chain.stream({
                            "context": context_text,
                            "chat_history": st.session_state.chat_history,
                            "input": standalone_q
                        }))

                if st.session_state.get("last_search_results"):
                    with st.expander("ğŸ” æ£€ç´¢ç»“æœæº¯æº (Top 5)", expanded=False):
                        for idx, (doc, score) in enumerate(st.session_state.last_search_results, 1):
                            score_float = round(float(score), 3)
                            color = "green" if score_float > 0.5 else "orange" if score_float > 0 else "gray"
                            st.markdown(f"""
                                <div style="padding: 8px; margin: 4px 0; border-radius: 6px; background-color: #f8fafc;">
                                    <strong>ç¬¬ {idx} æ¡åŒ¹é…ç»“æœï¼š</strong><br>
                                    <strong>æ–‡ä»¶ï¼š</strong>{doc.metadata.get('source_file', 'æœªçŸ¥')}<br>
                                    <strong>è¯­ä¹‰å…³è”åº¦ï¼š</strong><span style="color:{color};">[{score_float}]</span><br>
                                    <div style="margin-top: 4px; font-size: 0.9rem; color: #475569;">
                                        {doc.page_content[:200]}...
                                    </div>
                                </div>
                            """, unsafe_allow_html=True)

            # æ›´æ–°å†å²
            st.session_state.chat_history.extend([HumanMessage(content=user_input), AIMessage(content=answer)])
            st.session_state.messages.append({"role": "assistant", "content": answer})

            total_time = time.perf_counter() - total_start_time
            st.markdown(f"""
                <div class="debug-info">
                    ğŸ“Š è°ƒè¯•ä¿¡æ¯ | LLM è°ƒç”¨ {llm_call_count} æ¬¡ | æ€»è€—æ—¶ {total_time:.2f} ç§’
                </div>
            """, unsafe_allow_html=True)

    # ä¿å­˜å½“å‰å¯¹è¯
    st.session_state.conversations[st.session_state.current_conversation] = {
        "messages": st.session_state.messages,
        "chat_history": st.session_state.chat_history
    }